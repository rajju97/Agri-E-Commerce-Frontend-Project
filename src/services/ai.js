import { GoogleGenerativeAI } from "@google/generative-ai";

const API_KEY = import.meta.env.VITE_GEMINI_API_KEY;

// Initialize Gemini
// Note: If API_KEY is missing, this might throw or fail later.
// We'll handle it inside the function.
const genAI = API_KEY ? new GoogleGenerativeAI(API_KEY) : null;

export const generateProductDescription = async (prompt) => {
  if (!genAI) {
    console.warn("Gemini API Key is missing.");
    return "Sample product description generated by AI (Placeholder). Please configure VITE_GEMINI_API_KEY.";
  }
  try {
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
    const result = await model.generateContent(prompt);
    const response = await result.response;
    return response.text();
  } catch (error) {
    console.error("Error generating description:", error);
    return "Error generating description. Please try again.";
  }
};

export const generateProductImage = async (prompt) => {
  // Currently, the Google Generative AI JS SDK does not support direct text-to-image generation
  // in the same way as text-to-text. It typically requires Vertex AI or other endpoints.
  // This is a placeholder that simulates the "Nanobana" (or Gemini) image generation request.

  console.log("Generating image for:", prompt);

  // Simulate API delay
  await new Promise(resolve => setTimeout(resolve, 2000));

  // Return a placeholder image based on keywords (simple mock logic)
  // In a real implementation, this would fetch from an image generation API.

  return `https://placehold.co/500x500?text=${encodeURIComponent(prompt.substring(0, 20))}`;
};
